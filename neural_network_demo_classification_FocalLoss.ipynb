{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network From Scratch\n",
    "## classification demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from andreiNet.neural_net import NeuralNetwork\n",
    "from andreiNet.utils import norm_data, one_hot_encode\n",
    "from andreiNet.metrics import Accuracy\n",
    "from andreiNet.losses import Loss, CrossEntropy, FocalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Cross Entropy = - \\frac{1}{N} \\sum_{k} \\sum_{i} y_{i, k} \\log(p_{i, k}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Focal Loss = - \\frac{1}{N} \\sum_{k} \\sum_{i} \\alpha_t (1 - p^t_{i, k})^{\\gamma} y_{i, k} \\log(p^t_{i, k}) $$\n",
    "$$ p^t_{i, k} = y_{i, k} \\times p_{i, k} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy: 0.9830564281864164\n",
      "focal loss (gamma=0.0): 0.9830564281864164\n",
      "focal loss (gamma=2.0): 0.5310705044561551\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([[1, 0, 0], [0, 1, 0]])\n",
    "y_pred = np.array([[0.7, 0.2, 0.1], [0.2, 0.2, 0.6]])\n",
    "\n",
    "ce = CrossEntropy().loss(y_true, y_pred)\n",
    "print(\"cross entropy: {}\".format(ce))\n",
    "\n",
    "gamma = 0.0\n",
    "fl = FocalLoss(gamma=gamma).loss(y_true, y_pred)\n",
    "print(\"focal loss (gamma={}): {}\".format(gamma, fl))\n",
    "\n",
    "gamma = 2.0\n",
    "fl = FocalLoss(gamma=gamma).loss(y_true, y_pred)\n",
    "print(\"focal loss (gamma={}): {}\".format(gamma, fl))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Easy Case, Correctly Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy: 0.10536051565782628\n",
      "focal loss (gamma=2.0): 0.0010536051565782623\n",
      "ce / fl = 100.00000000000006\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([[1, 0, 0], ])\n",
    "y_pred = np.array([[0.9, 0.05, 0.05], ])\n",
    "\n",
    "ce = CrossEntropy().loss(y_true, y_pred)\n",
    "print(\"cross entropy: {}\".format(ce))\n",
    "\n",
    "fl = FocalLoss(gamma=gamma).loss(y_true, y_pred)\n",
    "print(\"focal loss (gamma={}): {}\".format(gamma, fl))\n",
    "\n",
    "print('ce / fl = {}'.format(ce / fl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Hard Case, Correctly Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy: 0.916290731874155\n",
      "focal loss (gamma=2.0): 0.3298646634746958\n",
      "ce / fl = 2.7777777777777777\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([[1, 0, 0], ])\n",
    "y_pred = np.array([[0.4, 0.3, 0.3], ])\n",
    "\n",
    "ce = CrossEntropy().loss(y_true, y_pred)\n",
    "print(\"cross entropy: {}\".format(ce))\n",
    "\n",
    "fl = FocalLoss(gamma=gamma).loss(y_true, y_pred)\n",
    "print(\"focal loss (gamma={}): {}\".format(gamma, fl))\n",
    "\n",
    "print('ce / fl = {}'.format(ce / fl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Incorrectly Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy: 1.2039728043259361\n",
      "focal loss (gamma=2.0): 0.5899466741197086\n",
      "ce / fl = 2.0408163265306127\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([[1, 0, 0], ])\n",
    "y_pred = np.array([[0.3, 0.4, 0.4], ])\n",
    "\n",
    "ce = CrossEntropy().loss(y_true, y_pred)\n",
    "print(\"cross entropy: {}\".format(ce))\n",
    "\n",
    "fl = FocalLoss(gamma=gamma).loss(y_true, y_pred)\n",
    "print(\"focal loss (gamma={}): {}\".format(gamma, fl))\n",
    "\n",
    "print('ce / fl = {}'.format(ce / fl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: (very) Incorrectly Classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross entropy: 2.995732273553991\n",
      "focal loss (gamma=2.0): 2.7036483768824766\n",
      "ce / fl = 1.10803324099723\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array([[1, 0, 0], ])\n",
    "y_pred = np.array([[0.05, 0.9, 0.05], ])\n",
    "\n",
    "ce = CrossEntropy().loss(y_true, y_pred)\n",
    "print(\"cross entropy: {}\".format(ce))\n",
    "\n",
    "fl = FocalLoss(gamma=gamma).loss(y_true, y_pred)\n",
    "print(\"focal loss (gamma={}): {}\".format(gamma, fl))\n",
    "\n",
    "print('ce / fl = {}'.format(ce / fl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-20.,  -0.,  -0.]]), array([[-20.,  -0.,  -0.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossEntropy().grad(y_true, y_pred), FocalLoss(gamma=0.0).grad(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7036483768824766"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FocalLoss().eval(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cross_entropy'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(CrossEntropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trn.shape = (105, 4), X_test.shape = (45, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load Iris Dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  \n",
    "y = iris.target\n",
    "\n",
    "# We will also split the dataset into training and testing so we can evaluate the kNN classifier\n",
    "X_trn, X_test, y_trn, y_test = train_test_split(X, \n",
    "                                                y, \n",
    "                                                test_size=0.30, \n",
    "                                                random_state=0,\n",
    "                                                stratify=y)\n",
    "\n",
    "print(\"X_trn.shape = {}, X_test.shape = {}\".format(X_trn.shape, X_test.shape))\n",
    "X_trn_norm, (trn_mean, trn_std) = norm_data(X_trn)\n",
    "X_test_norm = (X_test - trn_mean) / trn_std\n",
    "\n",
    "accuracy = Accuracy().eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "activation = 'relu'\n",
    "batch_size = 50\n",
    "random_state = 0\n",
    "lr = 0.001\n",
    "n_epochs = 10000\n",
    "metrics = ['accuracy']\n",
    "weight_init = 'he_norm'\n",
    "hidden_layers = (50, 60, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10000: final trn loss = 0.057764856039952545 trn metrics {'accuracy': 0.9714285714285714, cross_entropy: 0.057764856039952545, cross_entropy: 0.057764856039952545}\n",
      "val metrics {'accuracy': 0.9555555555555556, cross_entropy: 0.08578959627346104, cross_entropy: 0.08578959627346104}\n",
      "setting best model from epoch 9370\n",
      "--- 18.18484926223755 seconds ---\n",
      "trn acc 0.9714285714285714\n",
      "test acc 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "loss = CrossEntropy() #'cross_entropy'\n",
    "\n",
    "\n",
    "# Train model\n",
    "\n",
    "# Initialize model\n",
    "start_time = time.time()\n",
    "nn = NeuralNetwork(hidden=hidden_layers, \n",
    "                   init_weights=weight_init,\n",
    "                   loss=loss,\n",
    "                   activation=activation,\n",
    "                   shuffle=True,\n",
    "                   random_state=random_state,\n",
    "                   metrics=metrics,\n",
    "                   verbose=False\n",
    "                   )\n",
    "\n",
    "nn.train(X_trn_norm, y_trn, \n",
    "         n_epochs=n_epochs,\n",
    "         batch_size=batch_size, \n",
    "         early_stop=None, # ('accuracy', 500),\n",
    "         lr=lr, \n",
    "         val_data=(X_test_norm, y_test),\n",
    "         save_best=True)\n",
    "\n",
    "# Run Inference\n",
    "y_pred_trn = nn.predict(X_trn_norm).argmax(axis=1)\n",
    "y_pred_test = nn.predict(X_test_norm).argmax(axis=1)\n",
    "\n",
    "delta_1 = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (delta_1))\n",
    "print('trn acc', accuracy(y_pred_trn, y_trn))\n",
    "print('test acc', accuracy(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.trn_metric_hist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10000: final trn loss = 0.10120441372196637 trn metrics {'accuracy': 0.9333333333333333, cross_entropy: 0.2957503355502163, cross_entropy: 0.2957503355502163, focal_loss: 0.10120441372196637}\n",
      "val metrics {'accuracy': 0.9555555555555556, cross_entropy: 0.32318289911473963, cross_entropy: 0.32318289911473963, focal_loss: 0.11839935843272466}\n",
      "setting best model from epoch 9992\n",
      "--- 22.939999103546143 seconds ---\n",
      "trn acc 0.9333333333333333\n",
      "test acc 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "loss = FocalLoss(gamma=1.0) #'cross_entropy'\n",
    "\n",
    "\n",
    "# Train model\n",
    "\n",
    "# Initialize model\n",
    "del nn\n",
    "start_time = time.time()\n",
    "nn = NeuralNetwork(hidden=hidden_layers, \n",
    "                   init_weights=weight_init,\n",
    "                   loss=loss,\n",
    "                   activation=activation,\n",
    "                   shuffle=True,\n",
    "                   random_state=random_state,\n",
    "                   metrics=metrics,\n",
    "                   verbose=False\n",
    "                   )\n",
    "\n",
    "nn.train(X_trn_norm, y_trn, \n",
    "         n_epochs=n_epochs,\n",
    "         batch_size=batch_size, \n",
    "         early_stop=None, # ('accuracy', 500),\n",
    "         lr=lr, \n",
    "         val_data=(X_test_norm, y_test),\n",
    "         save_best=True)\n",
    "\n",
    "# Run Inference\n",
    "y_pred_trn = nn.predict(X_trn_norm).argmax(axis=1)\n",
    "y_pred_test = nn.predict(X_test_norm).argmax(axis=1)\n",
    "\n",
    "delta_1 = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (delta_1))\n",
    "print('trn acc', accuracy(y_pred_trn, y_trn))\n",
    "print('test acc', accuracy(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.trn_metric_hist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot neural network history\n",
    "fig_size = (12, 5)\n",
    "x_axis = np.arange(len(nn.trn_metric_hist[str(FocalLoss(gamma=1.0) )]))\n",
    "metrics = nn.trn_metric_hist.keys()\n",
    "fig, axs = plt.subplots(1, 2, figsize=fig_size)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    axs[i].plot(x_axis, nn.trn_metric_hist[metric], c='r', linewidth=2, label='trn')\n",
    "    axs[i].plot(x_axis, nn.val_metric_hist[metric], c='b', linewidth=2, label='val')\n",
    "    axs[i].set_xlabel('epoch', fontsize=18)\n",
    "    axs[i].set_ylabel(metric, fontsize=18)\n",
    "    if metric == loss:\n",
    "        axs[i].set_ylabel(metric+' (loss)', \n",
    "                          fontsize=18)\n",
    "    axs[i].legend(prop={'size': 14})\n",
    "    \n",
    "plt.suptitle('andreiNet model history', fontsize=22)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
