{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from andreiNet.neural_net import NeuralNetwork\n",
    "from andreiNet.utils import norm_data, one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trn.shape = (253, 4), X_test.shape = (253, 4)\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "\n",
    "X = boston.data  \n",
    "y = boston.target\n",
    "\n",
    "#Choose Features \\\n",
    "feature_idxs = [0, 1, 2, 3] # SET FEATURES BY INDEX <------------------\n",
    "\n",
    "#feature_names = ['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width']\n",
    "#xlbl, ylbl = feature_names[feature_idxs[0]], feature_names[feature_idxs[1]] \n",
    "# We will also split the dataset into training and testing so we can evaluate the kNN classifier\n",
    "X_trn_, X_test_, y_trn, y_test = train_test_split(X, \n",
    "                                                 y, \n",
    "                                                 test_size=0.5, \n",
    "                                                 random_state=2)\n",
    "X_trn, X_test = X_trn_[:, feature_idxs], X_test_[:, feature_idxs]\n",
    "\n",
    "print(\"X_trn.shape = {}, X_test.shape = {}\".format(X_trn.shape, X_test.shape))\n",
    "X_trn_norm, (trn_mean, trn_std) = norm_data(X_trn)\n",
    "X_test_norm = (X_test - trn_mean) / trn_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "activation = 'ReLU'\n",
    "batch_size = 50\n",
    "random_state = 0\n",
    "lr = 0.001\n",
    "n_epochs = 1000\n",
    "loss = 'cross_entropy'\n",
    "metrics = ['accuracy']\n",
    "weight_init = 'he_norm'\n",
    "hidden_layers = (100, )\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "nn = NeuralNetwork(hidden=hidden_layers, \n",
    "                   init_weights=weight_init,\n",
    "                   loss = loss,\n",
    "                   activation=activation,\n",
    "                   shuffle=True,\n",
    "                   random_state=random_state,\n",
    "                   metrics=metrics,\n",
    "                   verbose=False\n",
    "                   )\n",
    "nn.train(X_trn_norm, y_trn, \n",
    "         n_epochs=n_epochs,\n",
    "         batch_size=batch_size, \n",
    "         early_stop=None, #('accuracy', 100),\n",
    "         lr=lr, \n",
    "         val_data=(X_test_norm, y_test),\n",
    "         save_best=False)\n",
    "y_pred_trn = nn.predict(X_trn_norm).argmax(axis=1)\n",
    "y_pred_test = nn.predict(X_test_norm).argmax(axis=1)\n",
    "delta_1 = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (delta_1))\n",
    "print('trn acc', accuracy_score(y_pred_trn, y_trn))\n",
    "print('test acc', accuracy_score(y_pred_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
