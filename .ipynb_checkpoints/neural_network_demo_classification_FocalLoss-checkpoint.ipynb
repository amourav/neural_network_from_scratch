{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network From Scratch\n",
    "## classification demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from andreiNet.neural_net import NeuralNetwork\n",
    "from andreiNet.utils import norm_data, one_hot_encode\n",
    "from andreiNet.metrics import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_trn.shape = (75, 4), X_test.shape = (75, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load Iris Dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data  \n",
    "y = iris.target\n",
    "\n",
    "# We will also split the dataset into training and testing so we can evaluate the kNN classifier\n",
    "X_trn, X_test, y_trn, y_test = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  test_size=0.50, \n",
    "                                                  random_state=0,\n",
    "                                                  stratify=y)\n",
    "\n",
    "print(\"X_trn.shape = {}, X_test.shape = {}\".format(X_trn.shape, X_test.shape))\n",
    "X_trn_norm, (trn_mean, trn_std) = norm_data(X_trn)\n",
    "X_test_norm = (X_test - trn_mean) / trn_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from andreiNet.Initialization import HeNorm, Zeros\n",
    "from andreiNet.losses import CrossEntropy, Loss\n",
    "from andreiNet.activations import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000: final trn loss = 0.24205808729695827 trn metrics {'accuracy': 0.8933333333333333, cross_entropy: 0.24205808729695827}\n",
      "val metrics {'accuracy': 0.9066666666666666, cross_entropy: 0.2632714423510028}\n",
      "setting best model from epoch 1000\n",
      "--- 1.7055294513702393 seconds ---\n",
      "trn acc 0.8933333333333333\n",
      "test acc 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "activation = ReLU() #'ReLU'\n",
    "batch_size = 50\n",
    "random_state = 0\n",
    "lr = 0.001\n",
    "n_epochs = 1000\n",
    "loss = CrossEntropy() #'cross_entropy'\n",
    "metrics = ['accuracy']\n",
    "weight_init = HeNorm() #'he_norm'\n",
    "hidden_layers = (50, 60, 50)\n",
    "\n",
    "# Initialize model\n",
    "start_time = time.time()\n",
    "nn = NeuralNetwork(hidden=hidden_layers, \n",
    "                   init_weights=weight_init,\n",
    "                   init_bias=Zeros(),\n",
    "                   loss=loss,\n",
    "                   activation=activation,\n",
    "                   shuffle=True,\n",
    "                   random_state=random_state,\n",
    "                   metrics=metrics,\n",
    "                   verbose=False\n",
    "                   )\n",
    "\n",
    "# Train model\n",
    "nn.train(X_trn_norm, y_trn, \n",
    "         n_epochs=n_epochs,\n",
    "         batch_size=batch_size, \n",
    "         early_stop=None, # ('accuracy', 500),\n",
    "         lr=lr, \n",
    "         val_data=(X_test_norm, y_test),\n",
    "         save_best=True)\n",
    "\n",
    "# Run Inference\n",
    "y_pred_trn = nn.predict(X_trn_norm).argmax(axis=1)\n",
    "y_pred_test = nn.predict(X_test_norm).argmax(axis=1)\n",
    "\n",
    "delta_1 = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (delta_1))\n",
    "print('trn acc', accuracy(y_pred_trn, y_trn))\n",
    "print('test acc', accuracy(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trn_oh = one_hot_encode(y_trn, len(set(y_trn)))\n",
    "y_trn_pred_oh = nn.predict(X_trn_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = loss.loss(y_trn_oh, y_trn_pred_oh)\n",
    "ce_grad = loss.grad(y_trn_oh, y_trn_pred_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2420580872969582\n",
      "[-0.0134586 -0.        -0.       ]\n"
     ]
    }
   ],
   "source": [
    "print(ce)\n",
    "print(ce_grad[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl = FocalLoss(gamma=0.0, alpha='inverse_freq')\n",
    "fl_loss = fl.loss(y_trn_oh, y_trn_pred_oh)\n",
    "fl_grad = fl.grad(y_trn_oh, y_trn_pred_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trn_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00968232349187833\n",
      "[-0.00053834 -0.         -0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(ce/25)\n",
    "print(ce_grad[0]/25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00968232349187833, array([-0.00053834, -0.        , -0.        ]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_loss, fl_grad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot neural network history\n",
    "#loss = 'cross_entropy'\n",
    "fig_size = (12, 5)\n",
    "x_axis = np.arange(len(nn.trn_metric_hist[loss]))\n",
    "metrics = nn.trn_metric_hist.keys()\n",
    "fig, axs = plt.subplots(1, 2, figsize=fig_size)\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    axs[i].plot(x_axis, nn.trn_metric_hist[metric], c='r', linewidth=2, label='trn')\n",
    "    axs[i].plot(x_axis, nn.val_metric_hist[metric], c='b', linewidth=2, label='val')\n",
    "    axs[i].set_xlabel('epoch', fontsize=18)\n",
    "    axs[i].set_ylabel(metric, fontsize=18)\n",
    "    if metric == loss:\n",
    "        axs[i].set_ylabel(str(metric)+' (loss)', \n",
    "                          fontsize=18)\n",
    "    axs[i].legend(prop={'size': 14})\n",
    "    \n",
    "plt.suptitle('andreiNet model history', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Keras model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "np.random.seed(random_state)\n",
    "start_time = time.time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for l, hidden in enumerate(hidden_layers):\n",
    "    output_shape = hidden\n",
    "    if l==0:\n",
    "        input_shape = X_trn_norm.shape[1]\n",
    "    else:\n",
    "        input_shape = hidden_layers[l-1]\n",
    "    model.add(Dense(output_shape, activation=str(activation).lower(), \n",
    "                input_dim=input_shape, \n",
    "                kernel_initializer='he_normal'))\n",
    "    \n",
    "model.add(Dense(3, activation='softmax',))\n",
    "\n",
    "sgd = SGD(lr=lr, decay=0.0, momentum=0.00, nesterov=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "keras_hist = model.fit(X_trn_norm, one_hot_encode(y_trn, 3),\n",
    "                       epochs=n_epochs,\n",
    "                       validation_data=(X_test_norm, one_hot_encode(y_test, 3)),\n",
    "                       batch_size=batch_size,\n",
    "                       verbose=0)\n",
    "y_pred_trn = model.predict(X_trn_norm).argmax(axis=1)\n",
    "y_pred_test = model.predict(X_test_norm).argmax(axis=1)\n",
    "delta_2 = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (delta_2))\n",
    "print('trn acc', accuracy(y_pred_trn, y_trn))\n",
    "print('test acc', accuracy(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras training history\n",
    "fig_size = (12, 5)\n",
    "x_axis = np.arange(n_epochs)\n",
    "fig, axs = plt.subplots(1, 2, figsize=fig_size)\n",
    "\n",
    "axs[0].plot(x_axis, keras_hist.history['acc'], c='r', linewidth=2, label='trn')\n",
    "axs[0].plot(x_axis, keras_hist.history['val_acc'], c='b', linewidth=2, label='val')\n",
    "axs[0].set_xlabel('epoch', fontsize=18)\n",
    "axs[0].set_ylabel('accuracy', fontsize=18)\n",
    "axs[0].legend(prop={'size': 14})\n",
    "\n",
    "axs[1].plot(x_axis, keras_hist.history['loss'], c='r', linewidth=2, label='trn')\n",
    "axs[1].plot(x_axis, keras_hist.history['val_loss'], c='b', linewidth=2, label='val')\n",
    "axs[1].set_xlabel('epoch', fontsize=18)\n",
    "axs[1].set_ylabel('categorical_crossentropy', fontsize=18)\n",
    "axs[1].legend(prop={'size': 14})\n",
    "\n",
    "plt.suptitle('Keras model history', fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare training time\n",
    "plt.figure(figsize=(6, 6))\n",
    "trn_times = [delta_1, delta_2]\n",
    "y_pos = [0, 1]\n",
    "plt.bar(y_pos, trn_times, color=['blue', 'red'])\n",
    "plt.xticks(y_pos, ['andreiNet', 'Keras'], fontsize=16) \n",
    "plt.ylabel('training time (sec)', fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
